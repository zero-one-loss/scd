{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for training binary activation neural network with bp by approximating  gradient for sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: Larq https://docs.larq.dev/larq/tutorials/mnist/\n",
    "Here my implementation is slightly different from larq. We clip the gradient by a threshold of a quarter of mean of absolute of the projection. Since we don't have batch normalization to restrict projections range before activation in each layer, set a fixed number for threshold makes training unstable.  Sign activation is difined in `core/cnn.py` or `core/cnn01.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySign(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.sign()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        inputs, = ctx.saved_tensors\n",
    "        # scale = math.sqrt(inputs.size(1)) * 3\n",
    "        grad_output[inputs.abs()>inputs.abs().mean()/4] = 0\n",
    "        return grad_output\n",
    "\n",
    "msign = MySign.apply\n",
    "\n",
    "#  x = torch.Tensor([0.1, -0.1])\n",
    "\n",
    "#  y = msign(x)\n",
    "\n",
    "#  y == [1, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can copy models (toy3srr100scale, toy3ssr100scale..etc) you defined in `core/cnn01.py` to `core/cnn.py`, train them through `train_bp.py` or `train_bce.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    python train_bce.py --aug 1 --n_classes 2 --no_bias 1 --seed 0 --version toy3srr100scale --lr 0.001 --target cifar10_binary_toy3srr100scale_nb2_bce_bp_0\n",
    "    \n",
    "    python train_bp.py --aug 1 --n_classes 10 --no_bias 1 --seed 0 --version toy3srr100scale --lr 0.001 --target cifar10_toy3srr100scale_nb2_mce_bp_0\n",
    "    \n",
    "or FP16\n",
    "\n",
    "    python train_bp.py --aug 1 --n_classes 10 --fp16 --no_bias 1 --seed 0 --version toy3srr100scale --lr 0.001 \n",
    "    --target cifar10_toy3srr100scale_nb2_mce_bp_fp16_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (scd)",
   "language": "python",
   "name": "pycharm-ae4fd5d8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
