{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial of using Stochastic Coordinate Descent to train a sign activated neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `main` directory, there are two scripts for **binary classification with sigmoid activation** and **multi-class classification with softmax**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Binary classification\n",
    "## SCD for MLP01\n",
    "\n",
    "    python train_cnn01_01.py --nrows 0.75 --localit 1 --updated_fc_features 128 --updated_fc_nodes 1 --width 100 --normalize 0 --fail_count 1 --loss 01loss --act sign --init normal --no_bias 0 --scale 1 --w-inc2 0.17 --version mlp01scale --seed 0 --iters 1000 --dataset cifar10 --n_classes 2 --cnn 0 --divmean 0 --target cifar10_binary_mlp01scale_sign_i1_bce_b200_lrc0.05_lrf0.17_nb2_nw0_dm0_upc1_upf1_ucf32_normal_0 --updated_fc_ratio 5 --verbose_iter 1\n",
    "    \n",
    "Explain:\n",
    "- 7500/10000 (batch_size)\n",
    "- feature pool size is 128\n",
    "- randomly update 1 node in each iteration\n",
    "- does not normalize the weight\n",
    "- 01 loss\n",
    "- weights initialization followed by normal distribution\n",
    "- all layers have bias\n",
    "- step-size 0.17\n",
    "- architecture version is mlp01scale\n",
    "- random seed is 0\n",
    "- 2 classes\n",
    "- --cnn 0 will flatten the vector\n",
    "- --divmean 0 does not normalize the data\n",
    "- --target model checkpoints and logs name\n",
    "- --verbose_iter print acc and loss every iterations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ABP for CNN model in binary\n",
    "\n",
    "For abp training, we have to define model variations for each phase.\n",
    "srrr -> ssrr -> sssr -> ssss Each phase is a warm start from previous phase\n",
    "\n",
    "    python train_cnn01_01.py --nrows 0.02 --localit 1 --updated_conv_features 32 --updated_fc_features 128 --updated_fc_nodes 1 --updated_conv_nodes 1 --width 100 --normalize 0 --percentile 1 --fail_count 1 --loss bce --act sign --fc_diversity 1 --init normal --no_bias 2 --scale 1 --w-inc1 0.025 --w-inc2 0.1 --version toy3srr100scale --seed 0 --iters 15000 --dataset cifar10 --n_classes 2 --cnn 1 --divmean 0 --target cifar10_binary_toy3srr100scale_abp_sign_i1_bce_b200_lrc0.025_lrf0.1_nb2_nw0_dm0_upc1_upf1_ucf32_normal_0 --updated_fc_ratio 10 --updated_conv_ratio 20 --verbose_iter 500 --freeze_layer 0 --lr 0.001 --bp_layer 4 --aug 1\n",
    "    \n",
    "    python train_cnn01_01.py --nrows 0.02 --localit 1 --updated_conv_features 32 --updated_fc_features 128 --updated_fc_nodes 1 --updated_conv_nodes 1 --width 100 --normalize 0 --percentile 1 --fail_count 1 --loss bce --act sign --fc_diversity 1 --init normal --no_bias 2 --scale 1 --w-inc1 0.025 --w-inc2 0.05 --version toy3ssr100scale --seed 0 --iters 15000 --dataset cifar10 --n_classes 2 --cnn 1 --divmean 0 --target cifar10_binary_toy3ssr100scale_abp_sign_i1_bce_b200_lrc0.025_lrf0.05_nb2_nw0_dm0_upc1_upf1_ucf32_normal_0 --updated_fc_ratio 10 --updated_conv_ratio 20 --verbose_iter 500 --freeze_layer 1 --resume --source cifar10_binary_toy3srr100scale_abp_sign_i1_bce_b200_lrc0.025_lrf0.1_nb2_nw0_dm0_upc1_upf1_ucf32_normal_0 --lr 0.001 --bp_layer 3  --aug 1  --reinit 3\n",
    "    \n",
    "    python train_cnn01_01.py --nrows 0.02 --localit 1 --updated_conv_features 32 --updated_fc_features 128 --updated_fc_nodes 1 --updated_conv_nodes 1 --width 100 --normalize 0 --percentile 1 --fail_count 1 --loss bce --act sign --fc_diversity 1 --init normal --no_bias 2 --scale 1 --w-inc1 0.05 --w-inc2 0.05 --version toy3sss100scale --seed 0 --iters 15000 --dataset cifar10 --n_classes 2 --cnn 1 --divmean 0 --target cifar10_binary_toy3sss100scale_abp_sign_i1_bce_b200_lrc0.05_lrf0.05_nb2_nw0_dm0_upc1_upf1_ucf32_normal_0 --updated_fc_ratio 10 --updated_conv_ratio 20 --verbose_iter 500 --freeze_layer 2 --resume --source cifar10_binary_toy3ssr100scale_abp_sign_i1_bce_b200_lrc0.025_lrf0.05_nb2_nw0_dm0_upc1_upf1_ucf32_normal_0  --lr 0.001 --bp_layer 2  --aug 1  --reinit 2\n",
    "    \n",
    "    python train_cnn01_01.py --nrows 0.02 --localit 1 --updated_conv_features 32 --updated_fc_features 128 --updated_fc_nodes 1 --updated_conv_nodes 1 --width 100 --normalize 0 --percentile 1 --fail_count 1 --loss bce --act sign --fc_diversity 1 --init normal --no_bias 2 --scale 1 --w-inc1 0.05 --w-inc2 0.7 --version toy3ssss100scale --seed 0 --iters 15000 --dataset cifar10 --n_classes 2 --cnn 1 --divmean 0 --target cifar10_binary_toy3ssss100scale_abp_sign_i1_bce_b200_lrc0.05_lrf0.7_nb2_nw0_dm0_upc1_upf1_ucf32_normal_0 --updated_fc_ratio 10 --updated_conv_ratio 20 --verbose_iter 500 --freeze_layer 3 --resume --source cifar10_binary_toy3sss100scale_abp_sign_i1_bce_b200_lrc0.05_lrf0.05_nb2_nw0_dm0_upc1_upf1_ucf32_normal_0 --lr 0.001 --bp_layer 1  --aug 1  --reinit 1\n",
    "    \n",
    "#### Notes\n",
    "- 200/10000 (batch size) Currently, 200 is a optimal batch size for ABP\n",
    "- --aug 1 for data augmentation, this is necessary.\n",
    "- For cnn model, set --cnn 1\n",
    "- freeze the layer trained by scd in the next phase, For example, in the first phase, no layer will be frozen, the first layer trained by scd. In the sencond phase, the first layer will be frozen and would not been trained any more, scd works on the second layer, but start from the third layer, there are 3 layers( the third, fourth, fifth) layer's weights will be re-initialized, so set --reinit 3. And they will be trained by bp, so set --bp_layer 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (scd)",
   "language": "python",
   "name": "pycharm-ae4fd5d8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
